{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOO1zMFMOl5O",
        "colab_type": "text"
      },
      "source": [
        "##**CNN classification on raw time series data**\n",
        "\n",
        "This notebook serves to classify the EEG data into tasks using the Shallow CNN. Three data augmentations are used:\n",
        "\n",
        "*   Subsampling\n",
        "*   Random Cropping\n",
        "*   Sequential Cropping\n",
        "\n",
        "The CNN is trained and evaluated on all of these different data augmentation methods. Data is sometimes split by person for analysis purposes. Due to RAM constraints, we restart the runtime after testing on a specific data augmentation method. To run a specific data augmentation method, only specific cells are required to run and will be specified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbtrr0n1hzIz",
        "colab_type": "text"
      },
      "source": [
        "Mount the google drive to create a valid path the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUX-5rzYhil8",
        "colab_type": "code",
        "outputId": "f9d041f3-adcd-4c01-ca6a-69fcb1c3c464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3M6cQMxo135",
        "colab_type": "text"
      },
      "source": [
        "Load in BCI dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHz5sjkWzkUi",
        "colab_type": "code",
        "outputId": "ca78d2e2-7d43-42b0-a66b-125fbc54401c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# load data\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "try:  \n",
        "  project_fname = '/content/drive/My Drive/c247/'\n",
        "  os.chdir(project_fname)\n",
        "  project_data_file = os.path.join(project_fname,'project_data/')\n",
        "except FileNotFoundError: \n",
        "  project_fname = '/content/drive/My Drive/Colab Notebooks/c247'\n",
        "  os.chdir(project_fname)\n",
        "  project_data_file = os.path.join(project_fname,'project_data/')\n",
        "\n",
        "from load_data import * \n",
        "from data_preprocessing import * \n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X_test, y_test, person_train_valid, X_train_valid, y_train_valid, person_test = load_data(dir_path = project_data_file)\n",
        "\n",
        "# normalize the data\n",
        "N_trials,N_eeg,N_bins,_ = X_train_valid.shape\n",
        "#X_train_valid = np.reshape(preprocessing.scale(np.reshape(X_train_valid,(N_trials*N_eeg,N_bins)),axis=1),(N_trials,N_eeg,N_bins,1))\n",
        "N_trials,N_eeg,N_bins,_ = X_test.shape\n",
        "#X_test = np.reshape(preprocessing.scale(np.reshape(X_test,(N_trials*N_eeg,N_bins)),axis=1),(N_trials,N_eeg,N_bins,1))\n",
        "\n",
        "num_test_samples = X_test.shape[0]\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000, 1)\n",
            "Test data shape: (443, 22, 1000, 1)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqo8fHQHpFSu",
        "colab_type": "text"
      },
      "source": [
        "Subsample data (data augmentation cell; just for experimenting with subsampled data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0NWHIl3vj3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_every = 4\n",
        "num_samples_per_trial = sample_every\n",
        "X_train_valid_subsample, y_train_valid_subsample = shuffle_data(*subsample_data(X_train_valid, y_train_valid,sample_every=sample_every))\n",
        "X_test_subsample, y_test_subsample = subsample_data(X_test, y_test,sample_every=sample_every)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH_DB-jHpUeV",
        "colab_type": "text"
      },
      "source": [
        "Split data by subject (Another optional cell; just for experimenting subject by subject)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-B8C0_1hO4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split into subject\n",
        "#no need to run this cell (free up ram)\n",
        "X_train_valid_person = [X_train_valid[person_train_valid.flatten()==i] for i in range(9)]\n",
        "y_train_valid_person = [y_train_valid[person_train_valid.flatten()==i] for i in range(9)]\n",
        "person_train_valid_person = [person_train_valid[person_train_valid.flatten()==i] for i in range(9)]\n",
        "\n",
        "X_test_person = [X_test[person_test.flatten()==i] for i in range(9)]\n",
        "y_test_person = [y_test[person_test.flatten()==i] for i in range(9)]\n",
        "person_test_person = [person_test[person_test.flatten()==i] for i in range(9)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waRrfNN8pc7C",
        "colab_type": "text"
      },
      "source": [
        "Crop the data with time windows specified by length and stride (another data augmentation cell; proven to greatly increase accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf6ATcTjvxwX",
        "colab_type": "code",
        "outputId": "e8c33ee1-53e2-45ed-a304-e32c881e9a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#crop samples to augment data\n",
        "\n",
        "N,eeg,time,_ = X_train_valid.shape\n",
        "sample_len=534\n",
        "stride=50\n",
        "num_crops = 10\n",
        "num_samples_per_trial = int((1000-sample_len)/stride + 1)\n",
        "num_samples = int(N*((1000-sample_len)/stride + 1))\n",
        "X_train_valid_crop, y_train_valid_crop, person_train_valid_crop = crop_data_sequentially(X_train_valid,y_train_valid,person_train_valid,sample_len=sample_len,stride=stride)\n",
        "X_test_crop, y_test_crop, person_test_crop = crop_data_sequentially(X_test,y_test,person_test,sample_len=sample_len,stride=stride)\n",
        "\n",
        "del X_train_valid\n",
        "del X_test\n",
        "#shuffle the data\n",
        "cv_idx=np.arange(X_train_valid_crop.shape[0])\n",
        "np.random.shuffle(cv_idx)\n",
        "X_train_valid_crop=X_train_valid_crop[cv_idx]\n",
        "y_train_valid_crop=y_train_valid_crop[cv_idx]\n",
        "person_train_valid_crop = person_train_valid_crop[cv_idx]\n",
        "\n",
        "print('Training/Valid Cropped data shape: {}'.format(X_train_valid_crop.shape))\n",
        "print('Training/Valid Cropped target shape: {}'.format(y_train_valid_crop.shape))\n",
        "print('Training/Valid Cropped person shape: {}'.format(person_train_valid_crop.shape))\n",
        "print('Test Cropped data shape: {}'.format(X_test_crop.shape))\n",
        "print('Test Cropped target shape: {}'.format(y_test_crop.shape))\n",
        "print('Test Cropped person shape: {}'.format(person_test_crop.shape))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid Cropped data shape: (21826, 22, 534, 1)\n",
            "Training/Valid Cropped target shape: (21826,)\n",
            "Training/Valid Cropped person shape: (21826,)\n",
            "Test Cropped data shape: (4571, 22, 534, 1)\n",
            "Test Cropped target shape: (4571,)\n",
            "Test Cropped person shape: (4571,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74eGW7Gfpoo0",
        "colab_type": "text"
      },
      "source": [
        "Split cropped data into subject "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WGQx61q2kxF",
        "colab_type": "code",
        "outputId": "a1d9062f-c664-426f-a75b-d2b5087d78e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "#split data in to subjects\n",
        "\n",
        "X_train_valid_crop_person = [X_train_valid_crop[person_train_valid_crop==i] for i in range(9)]\n",
        "y_train_valid_crop_person = [y_train_valid_crop[person_train_valid_crop==i] for i in range(9)]\n",
        "person_train_valid_crop_person = [person_train_valid_crop[person_train_valid_crop==i] for i in range(9)]\n",
        "\n",
        "X_test_crop_person =[X_test_crop[person_test_crop==i] for i in range(9)]\n",
        "y_test_crop_person = [y_test_crop[person_test_crop==i] for i in range(9)]\n",
        "person_test_crop_person = [person_test_crop[person_test_crop==i] for i in range(9)]\n",
        "\n",
        "#free up ram\n",
        "'''\n",
        "del X_train_valid_crop\n",
        "del X_test_crop\n",
        "'''\n",
        "\n",
        "print(X_train_valid_crop_person[0].shape)\n",
        "print(y_train_valid_crop_person[0].shape)\n",
        "print(person_train_valid_crop_person[0].shape)\n",
        "print(X_test_crop_person[0].shape)\n",
        "print(y_test_crop_person[0].shape)\n",
        "print(person_test_crop_person[0].shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3046, 22, 534, 1)\n",
            "(3046,)\n",
            "(3046,)\n",
            "(641, 22, 534, 1)\n",
            "(641,)\n",
            "(641,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O67th1CGp-UJ",
        "colab_type": "text"
      },
      "source": [
        "Connect to Google TPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGIv6ZptiDAd",
        "colab_type": "code",
        "outputId": "f4252032-69bc-458f-db77-f72ae0c93bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Tensorflow version 2.1.0\n",
            "Running on TPU  ['10.8.43.170:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: 10.8.43.170:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.8.43.170:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkIWFLsnGNfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import all needed modules\n",
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import Input,Dense,Conv2D,ReLU,ELU,\\\n",
        "  Activation,Flatten,AveragePooling2D,Softmax,BatchNormalization,MaxPooling2D,\\\n",
        "  Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,\\\n",
        "  ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "from datetime import datetime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcO36a7iqCIM",
        "colab_type": "text"
      },
      "source": [
        "Function used to specify Shallow CNN layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFqxS0I_9Jtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=40,\n",
        "                   kernel_size=(1,25),\n",
        "                   data_format='channels_last',\n",
        "                   kernel_regularizer=regularizers.l2(0.001),\n",
        "                   input_shape=(22,534,1))) #(22,510,40)\n",
        "  model.add(BatchNormalization(axis=-1))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Conv2D(filters=40,\n",
        "                  data_format='channels_last',\n",
        "                  kernel_size=(22,1),\n",
        "                  kernel_regularizer=regularizers.l2(0.001))) #(1,510,40)\n",
        "  model.add(BatchNormalization(axis=-1))\n",
        "  model.add(Activation(K.square,name='Square'))\n",
        "  model.add(AveragePooling2D(pool_size=(1,75),strides=(1,15)))#(1,30,40)\n",
        "  model.add(Activation(K.log,name='Log'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(100,\n",
        "                  kernel_regularizer=regularizers.l2(0.001),\n",
        "                  activation='relu'))\n",
        "  model.add(Dense(num_classes,\n",
        "                  activation='softmax'))\n",
        "  return model\n",
        "\n",
        "#initialize hyperparameters\n",
        "rand_seed = int(datetime.strftime(datetime.now(),\"%Y%m%d%H%M%S\"))\n",
        "batch_size=32\n",
        "num_folds=5\n",
        "num_classes = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFR9V87BqJ8i",
        "colab_type": "text"
      },
      "source": [
        "Cell to train on data split by person. Trains one model a person"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKj6jegZ1WHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "\n",
        "\n",
        "#lr = 9e-4\n",
        "\n",
        "rates = [4e-3,5e-3,5e-3,2e-3,7e-3,9e-4,8e-3,7e-4,1e-3]\n",
        "#Person Acc [0.72, 0.64, 0.78, 0.6, 0.48936170212765956, 0.46938775510204084, 0.66, 0.72, 0.7021276595744681]\n",
        "#Person Acc [0.7, 0.54, 0.74, 0.62, 0.44680851063829785, 0.3673469387755102, 0.62, 0.62, 0.6808510638297872]\n",
        "#Person Acc [0.78, 0.6, 0.74, 0.6, 0.6382978723404256, 0.4489795918367347, 0.74, 0.64, 0.6808510638297872]\n",
        "#person acc [0.72, 0.56, 0.78, 0.6, 0.5319148936170213, 0.4489795918367347, 0.72, 0.72, 0.6808510638297872]\n",
        "#Person Acc [0.74, 0.3, 0.76, 0.6, 0.46808510638297873, 0.46938775510204084, 0.7, 0.58, 0.6808510638297872]\n",
        "#Person Acc [0.66, 0.6, 0.68, 0.62, 0.6170212765957447, 0.46938775510204084, 0.6, 0.78, 0.6595744680851063] rates = [5e-3,7e-3,5e-3,2e-3,7e-3,5e-4,8e-3,7e-4,1e-3]\n",
        "#Person Acc [0.66, 0.56, 0.88, 0.58, 0.2978723404255319, 0.5306122448979592, 0.84, 0.78, 0.574468085106383] rates = [5e-3,7e-3,5e-3,2e-3,7e-3,6e-4,8e-3,7e-4,1e-3]\n",
        "#Person Acc [0.5, 0.28, 0.86, 0.4, 0.723404255319149, 0.4489795918367347, 0.58, 0.78, 0.7021276595744681]   rates = [5e-3,7e-3,5e-3,2e-3,7e-3,6e-4,8e-3,7e-4,1e-3] changed stride to 25\n",
        "#Person Acc [0.74, 0.54, 0.76, 0.64, 0.6170212765957447, 0.42857142857142855, 0.82, 0.78, 0.6808510638297872] rates = [4e-3,8e-3,5e-3,2e-3,7e-3,7e-4,8e-3,7e-4,1e-3]\n",
        "# Person Acc [0.8, 0.4, 0.74, 0.68, 0.6808510638297872, 0.46938775510204084, 0.62, 0.64, 0.6808510638297872] rates = [4e-3,8e-3,5e-3,2e-3,7e-3,7e-4,8e-3,7e-4,1e-3] initialzation to he normal\n",
        "#Person Acc [0.68, 0.4, 0.76, 0.66, 0.6595744680851063, 0.4489795918367347, 0.78, 0.78, 0.6382978723404256] rates = [4e-3,9e-3,5e-3,2e-3,7e-3,8e-4,8e-3,7e-4,1e-3]\n",
        "#[0.78,0.6,0.88,0.68,0.72,0.53,0.84,0.78,0.70]\n",
        "#current avg of best test acc: 0.72\n",
        "try:\n",
        "  del model\n",
        "  K.clear_session()\n",
        "except:\n",
        "  pass\n",
        "print('BATCH SIZE: {}'.format(batch_size))\n",
        "models = []\n",
        "person_accuracies = []\n",
        "avg_test_acc = np.zeros(9)\n",
        "lr_plateau = ReduceLROnPlateau(patience=4)\n",
        "early_stopper = EarlyStopping(patience=10)\n",
        "\n",
        "for person in range(9):\n",
        "\n",
        "  print('PERSON: {}'.format(person))\n",
        "  print('LEARNING RATE: {}'.format(rates[person]))\n",
        "\n",
        "  models.append(create_model())\n",
        "  optimizer = Adam(lr=rates[person])\n",
        "  \n",
        "  \n",
        "  \n",
        "  #optimizer = SGD(lr=lr, momentum=0.9,decay=1e-6)\n",
        "  models[person].compile(loss=categorical_crossentropy,optimizer=optimizer,metrics=['accuracy'])\n",
        "  #train model\n",
        "  \n",
        "  history = models[person].fit(x=X_train_valid_crop_person[person], y=to_categorical(y_train_valid_crop_person[person]), \n",
        "                      batch_size=batch_size, epochs=30, \n",
        "                      validation_split=1/num_folds,\n",
        "                      callbacks=[early_stopper, lr_plateau])\n",
        "\n",
        "  # Plot training & validation accuracy values\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # Plot training & validation loss values\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  correct = 0\n",
        "  N,_,_,_ = X_test_crop_person[person].shape\n",
        "  scores = np.zeros(num_classes)\n",
        "  test_data = X_test_crop_person[person]\n",
        "  test_label = y_test_crop_person[person]\n",
        "  for i in range(int(N/num_samples_per_trial)):\n",
        "    strt_idx = i*num_samples_per_trial\n",
        "    test_batch = test_data[strt_idx:strt_idx+num_samples_per_trial]\n",
        "    scores = np.mean(models[person].predict_on_batch(x=test_batch),axis=0)\n",
        "    pred = np.argmax(scores)\n",
        "    if pred == test_label[strt_idx]:\n",
        "          correct += 1\n",
        "  test_acc = correct/(N/num_samples_per_trial)\n",
        "  print('Test accuracy: {}'.format(test_acc))\n",
        "  person_accuracies.append(test_acc)\n",
        "\n",
        "print('Person Acc {}'.format(person_accuracies))\n",
        "print('Test Avg Mean Acc :{}'.format(np.mean(person_accuracies)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVW-5KdcqN_B",
        "colab_type": "text"
      },
      "source": [
        "Tests each model on the corresponding test set only for specific subject"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhduqAUwIZC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one model per person\n",
        "person_accuracies = []\n",
        "avg_test_acc = np.zeros(9)\n",
        "\n",
        "for person in range(9):\n",
        "  correct = 0\n",
        "  N,_,_,_ = X_test_crop_person[person].shape\n",
        "  scores = np.zeros(num_classes)\n",
        "  test_data = X_test_crop_person[person]\n",
        "  test_label = y_test_crop_person[person]\n",
        "\n",
        "  for i in range(int(N/num_samples_per_trial)):\n",
        "    strt_idx = i*num_samples_per_trial\n",
        "    test_batch = test_data[strt_idx:strt_idx+num_samples_per_trial]\n",
        "    scores = np.mean(model.predict_on_batch(x=test_batch),axis=0)\n",
        "    pred = np.argmax(scores)\n",
        "    if pred == test_label[strt_idx]:\n",
        "          correct += 1\n",
        "  test_acc = correct/(N/num_samples_per_trial)\n",
        "  print('Test accuracy: {}'.format(test_acc))\n",
        "  person_accuracies.append(test_acc)\n",
        "\n",
        "print('Person Acc {}'.format(person_accuracies))\n",
        "print('Test Avg Mean Acc :{}'.format(np.mean(person_accuracies)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U_5s2YTqRIn",
        "colab_type": "text"
      },
      "source": [
        "Averages all model confidence outputs for entire test set. Does not perform well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjm3Sq4oIZXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model ensembling: train multiple models and average their predictions on entire test set\n",
        "#test_avg_ensembling  = 0.42 when each model trained to one person\n",
        "#try training multiple modesl on entire dataset and then ensembling together\n",
        "avg_test_ensemble = []\n",
        "correct=0\n",
        "test_data=X_test_crop\n",
        "test_label=y_test_crop\n",
        "\n",
        "for i in range(3):\n",
        "  strt_idx = i*num_samples_per_trial\n",
        "  scores = np.zeros((num_classes))\n",
        "  test_batch = test_data[strt_idx:strt_idx+num_samples_per_trial]\n",
        "  for person in range(9):\n",
        "    model_ensemble = models[person]\n",
        "    score=np.zeros(4)\n",
        "    score += np.mean(model_ensemble.predict_on_batch(x=test_batch),axis=0)\n",
        "    scores+=score\n",
        "    print(score)\n",
        "  pred = np.argmax(scores)\n",
        "  if pred == test_label[strt_idx]:\n",
        "    correct += 1\n",
        "\n",
        "print('Test_acc_avg_ensemble: {}'.format(correct/(N/num_samples_per_trial)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6QwGUWqqcL6",
        "colab_type": "text"
      },
      "source": [
        "Cell to train on cropped data (not split by subject)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OKJojqBdhRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reset model variable to train another one\n",
        "try:\n",
        "  del model\n",
        "  K.clear_session()\n",
        "except:\n",
        "  pass\n",
        "  \n",
        "model = create_model()\n",
        "optimizer = Adam(lr=2e-3)\n",
        "\n",
        "model.compile(loss=categorical_crossentropy,optimizer=optimizer,metrics=['accuracy'])\n",
        "plot_model(model,'cnn_baseline.png',show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfjZXWakQXxz",
        "colab_type": "text"
      },
      "source": [
        "Trains Shallow CNN on entire training cropped set. Utilizes ReduceLRonPlateau and EarlyStopping callbacks to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30MZNbtl1V-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#introduced l1 regularization to spatial convolution lr=1e-3\n",
        "#Test acc per person: [0.62       0.34       0.78       0.46       0.46808511 0.46938776 0.74       0.8        0.74468085] Avg test acc: 0.6024615236165389\n",
        "#raise lr to 2e-3 set ReduceLROnPlateau patience to 2\n",
        "#Test acc per person: [0.58       0.46       0.82       0.58       0.46808511 0.3877551 0.66       0.72       0.63829787] Avg test acc: 0.59045978675158\n",
        "#removed l1 regularization\n",
        "#Test acc per person: [0.6        0.48       0.82       0.6        0.40425532 0.53061224 0.76       0.84       0.65957447] Avg test acc: 0.6327157813480002\n",
        "#Adam lr=9e-4 l2 reg=0.01\n",
        "#Test acc per person: [0.64       0.42       0.72       0.54       0.4893617  0.46938776 0.64       0.7        0.74468085] Avg test acc: 0.5959367009215034\n",
        "#changed sample len to 534 to perfectly mimic paper changed lr plateau patience to 3\n",
        "#Test acc per person: [0.71762871 0.44       0.88       0.54       0.40425532 0.51020408 0.56       0.68       0.65957447]Avg test acc: 0.599073619334989\n",
        "#added relu layer in between conv layers Test acc per person: [0.65522621 0.34       0.66       0.52       0.5106383  0.36734694 0.52       0.7        0.57446809] Avg test acc: 0.5386310589780661\n",
        "#removed relu added dense layer Test acc per person: [0.74882995 0.32       0.7        0.54       0.42553191 0.42857143 0.56       0.74       0.72340426]Avg test acc: 0.5762597279980359\n",
        "#used sgd at lr=1e-2 Test acc per person: [0.73322933 0.24       0.76       0.48       0.4893617  0.40816327 0.68       0.66       0.68085106] Avg test acc: 0.5701783733818595\n",
        "#switched back to adam removed dense layer and set lr=3e-3 Test acc per person: [0.74882995 0.38       0.72       0.52       0.38297872 0.44897959 0.56       0.62       0.70212766] Avg test acc: 0.5647684364459541\n",
        "#lecun_normal initialization Test acc per person: [0.74882995 0.38       0.72       0.52       0.38297872 0.44897959 0.56       0.62       0.70212766] Avg test acc: 0.5647684364459541\n",
        "#went for 80 epochs Test acc per person: [0.81123245 0.46       0.8        0.62       0.4893617  0.51020408 0.7        0.78       0.72340426] Avg test acc: 0.6549113875974927\n",
        "#changed l2 reg to 0.001 added dense layer Test acc per person: [0.73322933 0.68       0.84       0.58       0.4893617  0.53061224 0.74       0.78       0.76595745] Avg test acc: 0.6821289692230329\n",
        "#changed relu in dense layer to elu Test acc per person: [0.71762871 0.46       0.9        0.5        0.36170213 0.44897959 0.76       0.84       0.78723404] Avg test acc: 0.6417271630219674\n",
        "#changed back to relu and added batch norm layer after dense Test acc per person: [0.74882995 0.52       0.82       0.62       0.53191489 0.53061224 0.82       0.74       0.76595745] Avg test acc: 0.6774793931690688\n",
        "#removed added batch norm added temporal conv layer (took too long to train so colab just stopped)\n",
        "#changed batch size to 64 Test acc per person: [0.71762871 0.52       0.78       0.58       0.5106383  0.44897959 0.74       0.8        0.80851064] Avg test acc: 0.6561952481283504\n",
        "#change initialization to lecun normal Test acc per person: [0.74882995 0.5        0.82       0.56       0.53191489 0.48979592  0.76       0.86       0.80851064] Avg test acc: 0.6754501559422632\n",
        "#added relu after first conv layer Test acc per person: [0.68642746 0.44       0.78       0.68       0.4893617  0.48979592 0.64       0.72       0.68085106] Avg test acc: 0.6229373490470087 BUT 72% VAL ACCURACY\n",
        "#train on uncropped data Test acc per person: [0.6        0.42       0.74       0.62       0.72340426 0.44897959 0.6        0.64       0.59574468] Avg test acc: 0.5986809475563274\n",
        "#removed relu at first dense layer Test acc per person: [0.60842434 0.52       0.78       0.54       0.5106383  0.51020408 0.54       0.68       0.63829787] Avg test acc: 0.5919516209798776 | 77% VAL ACCURACY\n",
        "#changed num filters in first conv layer to 45 and reg to 0.001Test acc per person: [0.60842434 0.44       0.7        0.54       0.46808511 0.40816327 0.68       0.62       0.59574468] Avg test acc: 0.5622685988348493\n",
        "#removed relu at first conv layer and set reg to 0.001 Test acc per person: [0.703125   0.52       0.78       0.74       0.46808511 0.51020408 0.66       0.76       0.72340426] Avg test acc: 0.6516464937038645\n",
        "#changed num filters to 35 Test acc per person: [0.66       0.44       0.72       0.58       0.53191489 0.40816327 0.78       0.7        0.63829787] Avg test acc: 0.6064862256959521\n",
        "#change num filters back to 40 and made hidden layer 120 instead of 100 Test acc per person: [0.62       0.6        0.76       0.64       0.53191489 0.48979592 0.64       0.72       0.72340426] Avg test acc: 0.6361238963670576\n",
        "\n",
        "#train model\n",
        "batch_size=128\n",
        "lr_plateau = ReduceLROnPlateau(patience=4)\n",
        "early_stopper = EarlyStopping(patience=20)\n",
        "\n",
        "model_check_fname = os.path.join(project_fname,'model_checkpoints/','ckpt-CNN')\n",
        "time_rn = (datetime.strftime(datetime.now(),\"%H_%M_%S_%d_%m_%Y\"))\n",
        "model_filename = os.path.join(model_check_fname,'model_{}.h5'.format(time_rn))\n",
        "\n",
        "try:\n",
        "  history = model.fit(x=X_train_valid_crop, y=to_categorical(y_train_valid_crop), \n",
        "                      batch_size=batch_size, epochs=200, \n",
        "                      validation_split=1/num_folds,\n",
        "                      callbacks=[lr_plateau,early_stopper])\n",
        "except KeyboardInterrupt:\n",
        "  print('Keyboard Interrupted!')\n",
        "except Exception as e:\n",
        "  print('Unknown error: {}'.format(e))\n",
        "finally:\n",
        "  print('Saving model to {}'.format(model_filename))\n",
        "  model.save(model_filename)\n",
        "\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T50zZMbCQnfm",
        "colab_type": "text"
      },
      "source": [
        "Tests model on entire test cropped set. Averages model predictions on all the crops for one trial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3SoiPKVzC9B",
        "colab_type": "code",
        "outputId": "c8f971d3-923b-4ef2-dba3-bcb2959f51cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "#test on cropped data\n",
        "X_test_crop_person = [X_test_crop[person_test_crop.flatten()==i] for i in range(9)]\n",
        "y_test_crop_person = [y_test_crop[person_test_crop.flatten()==i] for i in range(9)]\n",
        "model_check_fname = os.path.join(project_fname,'model_checkpoints/','ckpt-CNN')\n",
        "model = load_model(os.path.join(model_check_fname,'model_18_00_20_10_03_2020_68%.h5'),\n",
        "                   custom_objects={'square':K.square,'log':K.log})\n",
        "\n",
        "person_acc = np.zeros(9)\n",
        "preds = np.empty((0))\n",
        "labels = np.empty((0))\n",
        "\n",
        "for person in range(9):\n",
        "  correct = 0\n",
        "  N,_,_,_ = X_test_crop_person[person].shape\n",
        "  scores = np.zeros(num_classes)\n",
        "  test_data = X_test_crop_person[person]\n",
        "  test_label = y_test_crop_person[person]\n",
        "  for i in range(int(N/num_samples_per_trial)):\n",
        "    strt_idx = i*num_samples_per_trial\n",
        "    test_batch = test_data[strt_idx:strt_idx+num_samples_per_trial]\n",
        "    raw_scores = model.predict_on_batch(x=test_batch)\n",
        "    scores = np.mean(raw_scores,axis=0)\n",
        "    pred = np.argmax(scores)\n",
        "\n",
        "    assert all(y == test_label[strt_idx] for y in test_label[strt_idx:strt_idx+num_samples_per_trial])\n",
        "    preds = np.append(preds,pred)\n",
        "    labels = np.append(labels,test_label[strt_idx])\n",
        "    if pred == test_label[strt_idx]:\n",
        "          correct += 1\n",
        "  test_acc = correct/(i+1)\n",
        "  person_acc[person]=test_acc\n",
        "print('Test acc per person: {}'.format(person_acc))\n",
        "print('Avg test acc: {}'.format(np.mean(person_acc)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test acc per person: [0.734375   0.68       0.84       0.58       0.4893617  0.53061224\n",
            " 0.74       0.78       0.76595745]\n",
            "Avg test acc: 0.6822562659815699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdI3huGQ2kD",
        "colab_type": "text"
      },
      "source": [
        "Create and display the confusion matrix for the model on sequentially cropped data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UES2kQRcMuhY",
        "colab_type": "code",
        "outputId": "1c6141bb-672c-45ba-a0d8-60f1625c2396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "display_labels = ['Left hand', 'Right hand','Foot','Tongue']\n",
        "confusion = confusion_matrix(y_true=labels, y_pred=preds, normalize='pred')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion,\n",
        "                              display_labels=display_labels)\n",
        "disp.plot()\n",
        "disp.ax_.set_xticklabels(display_labels, rotation=12)\n",
        "plt.title('Confusion Matrix of Shallow CNN by task')\n",
        "\n",
        "plt.savefig('CNN_confusionmatrix.png')\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAErCAYAAAAljMNyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpj35_ITqi-A",
        "colab_type": "text"
      },
      "source": [
        "Test on raw data (uncropped and not subsampled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPYU5rURISep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test on uncropped data\n",
        "person_acc = np.zeros(9)\n",
        "\n",
        "for person in range(9):\n",
        "  correct = 0\n",
        "  N,_,_,_ = X_test_person[person].shape\n",
        "  scores = np.zeros(num_classes)\n",
        "  test_data = X_test_person[person]\n",
        "  test_label = y_test_person[person]\n",
        "  scores = model.predict_on_batch(x=test_data)\n",
        "  pred = np.argmax(scores,axis=1)\n",
        "  correct = np.sum(pred == test_label)\n",
        "  test_acc = correct/(N)\n",
        "  person_acc[person]=test_acc\n",
        "print('Test acc per person: {}'.format(person_acc))\n",
        "print('Avg test acc: {}'.format(np.mean(person_acc)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Zw58XuqvpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  del model\n",
        "  K.clear_session()\n",
        "except:\n",
        "  pass\n",
        "  \n",
        "model = create_model()\n",
        "optimizer = Adam(lr=9e-4)\n",
        "#optimizer = SGD(lr=1e-3, momentum=0.9,decay=1e-6)\n",
        "model.compile(loss=categorical_crossentropy,optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTxuJnBKqvNc",
        "colab_type": "text"
      },
      "source": [
        "Trains on subsampled data (Overfits the subsampled data and does not generalize well to new data since training and validation data are closely correlated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBIhakXHpKq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train on subsampled data\n",
        "batch_size=32\n",
        "lr_plateau = ReduceLROnPlateau(patience=3)\n",
        "early_stopper = EarlyStopping(patience=8)\n",
        "history = model.fit(x=X_train_valid_subsample, y=to_categorical(y_train_valid_subsample), \n",
        "                    batch_size=batch_size, epochs=10, \n",
        "                    validation_split=1/num_folds,\n",
        "                    callbacks=[early_stopper,lr_plateau])\n",
        "\n",
        "try:\n",
        "  model_check_fname = os.path.join(project_fname, 'model_checkpoints/')\n",
        "  time_rn = (datetime.strftime(datetime.now(),\"%H_%M_%S_%d_%m_%Y\"))\n",
        "  model_filename = os.path.join(model_check_fname,'model{}.h5'.format(time_rn))\n",
        "  print('Saving model weights to {}'.format(model_filename))\n",
        "  model.save_weights(model_check_fname)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8QRomJRRB4C",
        "colab_type": "text"
      },
      "source": [
        "Test on subsampled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtD1bwGGpr6v",
        "colab_type": "code",
        "outputId": "69bc5c26-f12f-4d02-ea41-34516c6acbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#subsampling gives good training and validation loss but not good generalization\n",
        "#to test data at all since the training and validation data are closely correlated\n",
        "correct = 0\n",
        "print('num_samples_per_trial: {}'.format(num_samples_per_trial))\n",
        "N,_,_,_ = X_test_subsample.shape\n",
        "scores = np.zeros(num_classes)\n",
        "test_data = X_test_subsample\n",
        "test_label = y_test_subsample\n",
        "for i in range(int(N/num_samples_per_trial)):\n",
        "  strt_idx = i*num_samples_per_trial\n",
        "  test_batch = test_data[strt_idx:strt_idx+num_samples_per_trial]\n",
        "  scores = np.mean(model.predict_on_batch(x=test_batch),axis=0)\n",
        "  pred = np.argmax(scores)\n",
        "  if pred == test_label[strt_idx]:\n",
        "        correct += 1\n",
        "test_acc = correct/(N/num_samples_per_trial)\n",
        "print('Test acc: {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_samples_per_trial: 4\n",
            "Test acc: 0.4198645598194131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLpBXEyFr1Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}