import numpy as np
import os

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Silences the warning and error logs generated by TensorFlow

import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Flatten, LeakyReLU, Reshape, BatchNormalization


class StandardGAN:
    def __init__(self, channels=1):

        # Dataset features:
        self.channels = channels
        self.time_stamp = 1793
        self.eeg_shape = (self.time_stamp, self.channels)

        # Model specific parameters (Noise generation, Dropout for overfitting reduction, etc...):
        self.noise = 100
        self.dropout = 0.2
        self.alpha = 0.2
        self.momentum = 0.8

        # Choosing Adam optimiser for both generator and discriminator to feed in to the model:
        self.optimiser = Adam(0.0002, 0.2)  # Values from the EEG GAN paper found to be most optimal

        # Builds the Generator, Discriminator and the combined models:
        self.generator = self.make_generator()

        self.discriminator = self.make_discriminator()
        self.discriminator.compile(loss='binary_crossentropy',
                                   optimizer=self.optimiser,
                                   metrics=['accuracy'])

        self.combined = self.builder()
        self.combined.compile(loss='binary_crossentropy',
                              optimizer=self.optimiser)

        # Useful for creating a sample directory later
        self.dir = 'EEG_samples'

    def make_generator(self):
        '''
        Creates a generator model that takes in randomly generated noise, then uses
        3 Dense layers to return an image that is fed into the discriminator,
        which then distinguishes whether or not it is a real or fake one. Weights are adjusted
        accordingly such that it can eventually generate a real signal.
        :return: Model data tuple (generated noise sample, eeg img)
        '''
        model = Sequential()

        model.add(Dense(256, input_dim=self.noise))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(Dense(512))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(Dense(1024))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(BatchNormalization(momentum=self.momentum))
        model.add(Dense(np.prod(self.eeg_shape), activation='tanh'))
        model.add(Reshape(self.eeg_shape))
        assert model.output_shape == (None, 1793, self.channels)

        noise = Input(shape=(self.noise,))
        img = model(noise)

        return Model(noise, img)

    def make_discriminator(self):
        '''
        Creates a discriminator model that distingushes the fed images from generator,
        and also is trained using a training loop (see below). The Discriminator is a simple
        2 Dense layer Neural Netowrk that returns either a 'True' or 'False'. Values are then adjusted accordingly
        per epoch to update weights and biases such that it produces the right output (i.e. it can
        discriminate fake from real).
        :return: Model data tuple (image from generator, validity [true or false])
        '''
        model = Sequential()

        model.add(Flatten(input_shape=self.eeg_shape))
        model.add(Dense(512))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dense(256))
        model.add(LeakyReLU(alpha=self.alpha))
        model.add(Dense(1, activation='sigmoid'))

        img = Input(shape=self.eeg_shape)
        validity = model(img)

        return Model(img, validity)

    def builder(self):
        '''
        Function that allows us to build the combined generator + discriminator model.
        In return, this lets the generator eventually fool the discriminator (Where
        the discriminator takes in the generated signal and determines whether
        it's real or fake.)

        NOTE the discriminator.trainable = False, meaning that only the generator
        is trained here, while the discriminator is not trainable for the COMBINED
        model. This step takes place before model compilation.

        :return: Model data tuple(noise signal 'z', validity [True/False])
        '''
        z = Input(shape=(self.noise,))
        generated_eeg = self.generator(z)

        discriminator = self.discriminator
        discriminator.trainable = False

        validity = discriminator(generated_eeg)

        return Model(z, validity)

    def train(self, dataset, epochs=1000, batchsize=50, sample_interval=100):
        '''
        Training function used to allow us to pass all the training data per epoch to both the generator
        and discriminator. Notice how the discriminator is still trained per batch but not for the combined
        model.
        :param dataset: input/training dataset from load_and_preprocess
        :param epochs: number of epochs (1 epoch = 1 pass of all the training data) the models loop through
        :param batchsize: number of batches.
        :param sample_interval: at what interval do we present & save the results (see below)
        :return: None
        '''

        valid = np.ones((batchsize, 1))
        fake = np.zeros((batchsize, 1))

        gen_loss = []
        disc_loss = []

        for epoch in range(epochs):

            # Discriminator Training Loop
            idx = np.random.randint(0, dataset.shape[0], batchsize)
            signal = dataset[idx]

            noise = np.random.normal(0, 1, (batchsize, self.noise))

            gen_signals = self.generator.predict(noise)

            d_loss_real = self.discriminator.train_on_batch(signal, valid)
            d_loss_fake = self.discriminator.train_on_batch(gen_signals, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # Generator Training Loop
            noise = np.random.normal(0, 1, (batchsize, self.noise))

            # Combined model training where generator is trained to fool the discriminator
            g_loss = self.combined.train_on_batch(noise, valid)

            gen_loss.append(g_loss)
            disc_loss.append(d_loss[0])

            # Prints the Discriminator and Generator loss alongside accuracy
            # Per sample interval
            if epoch % sample_interval == 0:
                print("%d [Discriminator loss: %f, Accuracy: %.2f%%] [Generator loss: %f]" %
                      (epoch, d_loss[0], 100 * d_loss[1], g_loss))
                self.sample_eeg(epoch)

        plt.plot(gen_loss, 'r')
        plt.plot(disc_loss, 'b')
        plt.title('Discriminator & Generator Loss per Epoch')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.legend(['Generator Loss', 'Discriminator Loss'])
        plt.grid()
        plt.show()

    def sample_eeg(self, epoch):
        '''
        Allows us to retrieve the generated sample from the generator
        then plot it. See below comments for step by step procedure.
        :param epoch: Epoch number
        :return: None
        '''

        num_signals = 249
        noise = np.random.normal(0, 1, (num_signals, self.noise))
        gen_signal = self.generator.predict(noise)

        # Normalise
        gen_signal = 0.5 * gen_signal + 0.5

        # Plots the generated samples for the selected channels.
        # Recall the channels are chosen during the Load_and_Preprocess Script
        # Here they correspond to Fz, C3, Cz, C4 and Pz respectively.
        fig, axs = plt.subplots(5, sharex=True)
        fig.suptitle('Artificial EEG Data images per channel')
        fig.tight_layout()
        axs[0].imshow(gen_signal[:, :, 0])
        axs[0].set_title('Fz', size=10)
        axs[1].imshow(gen_signal[:, :, 1])
        axs[1].set_title('C3', size=10)
        axs[2].imshow(gen_signal[:, :, 2])
        axs[2].set_title('Cz', size=10)
        axs[3].imshow(gen_signal[:, :, 3])
        axs[3].set_title('C4', size=10)
        axs[4].imshow(gen_signal[:, :, 4])
        axs[4].set_title('Pz', size=10)

        # Save the generated samples within the current working dir
        # in a folder called 'EEG Samples', every 100 epochs.
        if not os.path.exists(self.dir):
            os.makedirs(self.dir)

        plt.savefig("%s/%d.png" % (self.dir, epoch))
        plt.close()

        return None

# load data
from braindecode.datautil.serialization import load_concat_dataset
from braindecode.datasets.base import BaseConcatDataset


datasets = []
for subject_id in subject_id_list:
    datasets.append(
            load_concat_dataset(
            path='../../data-file/bnci-raw/' + str(subject_id),
            preload=True,
            target_name=None,
            )
    )
dataset = BaseConcatDataset(datasets)


# *input window samples*
input_window_samples = 1000


# Create model

import torch
from braindecode.util import set_random_seeds
from braindecode.models import ShallowFBCSPNet

cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it
device = 'cuda' if cuda else 'cpu'
if cuda:
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

seed = 20200220  # random seed to make results reproducible
# Set random seed to be able to reproduce results
set_random_seeds(seed=seed, cuda=cuda)

n_classes = 4
# Extract number of chans and time steps from dataset
n_chans = dataset[0][0].shape[0]

model = ShallowFBCSPNet(
    n_chans,
    n_classes,
    input_window_samples=input_window_samples,
    final_conv_length=30,
)

# Send model to GPU
if cuda:
    model.cuda()

# And now we transform model with strides to a model
# that outputs dense prediction, so we can use it to obtain predictions for all crops.

from braindecode.models.util import to_dense_prediction_model, get_output_shape
to_dense_prediction_model(model)

# To know the modelsâ€™ receptive field, we calculate the shape of model output for a dummy input.

n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]

# Cut Compute Windows
# for cropped trials

from braindecode.datautil.windowers import create_windows_from_events

trial_start_offset_seconds = -0.5
# Extract sampling frequency, check that they are same in all datasets
sfreq = dataset.datasets[0].raw.info['sfreq']
assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])

# Calculate the trial start offset in samples.
trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)

# Create windows using braindecode function for this. It needs parameters to define how
# trials should be used.
windows_dataset = create_windows_from_events(
    dataset,
    trial_start_offset_samples=trial_start_offset_samples,
    trial_stop_offset_samples=0,
    window_size_samples=input_window_samples,
    window_stride_samples=n_preds_per_input,
    drop_last_window=False,
    preload=True
)
# Split dataset into train and valid
splitted = windows_dataset.split('session')
train_set = splitted['session_T']
valid_set = splitted['session_E']

# Instantiate an object (telling it how many channels does the dataset have)
# Else it defaults to one.
gan = StandardGAN(channels=5)
gan.train(train_set, batchsize=50, epochs=2500)
